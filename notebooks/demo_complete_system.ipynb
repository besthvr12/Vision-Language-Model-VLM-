{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Visual Commerce Platform - Complete Demo\n",
    "\n",
    "This notebook demonstrates all features of the platform:\n",
    "1. Data Loading & EDA\n",
    "2. Visual Search\n",
    "3. Attribute Extraction\n",
    "4. Quality Assessment\n",
    "5. Scene Understanding\n",
    "6. Recommendations\n",
    "7. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our modules\n",
    "from src.data.loader import DatasetLoader\n",
    "from src.data.preprocessor import ImagePreprocessor\n",
    "from src.models.embeddings import CLIPEmbedder\n",
    "from src.models.search import VisualSearchEngine\n",
    "from src.models.vlm_client import VLMClient\n",
    "from src.models.recommender import RecommendationEngine\n",
    "from src.evaluation.metrics import SearchMetrics, evaluate_search_system\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = DatasetLoader()\n",
    "\n",
    "# Create sample dataset\n",
    "df = loader.create_sample_dataset(num_samples=100)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset statistics\n",
    "stats = loader.get_statistics(df)\n",
    "\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(f\"Total Products: {stats['total_products']}\")\n",
    "print(f\"\\nPrice Range: ${stats['price_stats']['min']:.2f} - ${stats['price_stats']['max']:.2f}\")\n",
    "print(f\"Average Price: ${stats['price_stats']['mean']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Category distribution\n",
    "df['category'].value_counts().plot(kind='bar', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Products by Category')\n",
    "axes[0, 0].set_xlabel('Category')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# Color distribution\n",
    "df['baseColour'].value_counts().plot(kind='bar', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Products by Color')\n",
    "axes[0, 1].set_xlabel('Color')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "\n",
    "# Gender distribution\n",
    "df['gender'].value_counts().plot(kind='pie', ax=axes[1, 0], autopct='%1.1f%%')\n",
    "axes[1, 0].set_title('Products by Gender')\n",
    "\n",
    "# Price distribution\n",
    "df['price'].hist(bins=20, ax=axes[1, 1], edgecolor='black')\n",
    "axes[1, 1].set_title('Price Distribution')\n",
    "axes[1, 1].set_xlabel('Price ($)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CLIP embedder\n",
    "print(\"Loading CLIP model...\")\n",
    "embedder = CLIPEmbedder(model_name=\"ViT-B/32\")\n",
    "print(\"✓ CLIP loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VLM client (optional - requires API key)\n",
    "# Uncomment if you have API keys set up\n",
    "# vlm_client = VLMClient(provider=\"openai\", model=\"gpt-4o-mini\")\n",
    "print(\"Note: VLM client requires API keys. Set OPENAI_API_KEY in .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Embeddings for Visual Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demo, we'll generate embeddings from text descriptions\n",
    "# In production, you'd use actual product images\n",
    "\n",
    "print(\"Generating embeddings from product descriptions...\")\n",
    "descriptions = df.apply(\n",
    "    lambda x: f\"{x['category']} {x['baseColour']} {x['pattern']} for {x['gender']}\",\n",
    "    axis=1\n",
    ").tolist()\n",
    "\n",
    "embeddings = embedder.encode_text(descriptions)\n",
    "print(f\"✓ Generated {len(embeddings)} embeddings with shape {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Visual Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize search engine\n",
    "search_engine = VisualSearchEngine(embedding_dim=embeddings.shape[1])\n",
    "\n",
    "# Build index\n",
    "search_engine.build_index(\n",
    "    embeddings=embeddings,\n",
    "    product_ids=df['id'].tolist(),\n",
    "    metadata=df\n",
    ")\n",
    "\n",
    "print(\"✓ Search engine ready!\")\n",
    "print(search_engine.get_statistics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Visual Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search by text query\n",
    "query = \"red dress for women\"\n",
    "query_embedding = embedder.encode_text(query)\n",
    "\n",
    "results = search_engine.search(query_embedding, top_k=5)\n",
    "\n",
    "print(f\"Search results for: '{query}'\\n\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. {result['productDisplayName']}\")\n",
    "    print(f\"   Category: {result['category']} | Color: {result['baseColour']}\")\n",
    "    print(f\"   Price: ${result['price']:.2f} | Similarity: {result['similarity']:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with filters\n",
    "filtered_results = search_engine.search_with_filters(\n",
    "    query_embedding,\n",
    "    top_k=5,\n",
    "    filters={'category': 'Dress', 'gender': 'Women'}\n",
    ")\n",
    "\n",
    "print(f\"Filtered search results (Dresses for Women):\\n\")\n",
    "for i, result in enumerate(filtered_results, 1):\n",
    "    print(f\"{i}. {result['productDisplayName']} - ${result['price']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize recommendation engine\n",
    "recommender = RecommendationEngine(df)\n",
    "\n",
    "# Get a sample product\n",
    "sample_product_id = df.iloc[0]['id']\n",
    "sample_product = df[df['id'] == sample_product_id].iloc[0]\n",
    "\n",
    "print(f\"Source Product: {sample_product['productDisplayName']}\")\n",
    "print(f\"Category: {sample_product['category']} | Color: {sample_product['baseColour']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get content-based recommendations\n",
    "content_recs = recommender.content_based_recommendations(\n",
    "    sample_product_id,\n",
    "    embeddings,\n",
    "    df['id'].tolist(),\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "print(\"Content-Based Recommendations (Similar Products):\\n\")\n",
    "for i, rec in enumerate(content_recs, 1):\n",
    "    print(f\"{i}. {rec['productDisplayName']}\")\n",
    "    print(f\"   Similarity: {rec['similarity']:.3f} | Reason: {rec['reason']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get complementary recommendations\n",
    "comp_recs = recommender.complementary_recommendations(\n",
    "    sample_product_id,\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "print(\"Complementary Recommendations (Complete the Look):\\n\")\n",
    "for i, rec in enumerate(comp_recs, 1):\n",
    "    print(f\"{i}. {rec['productDisplayName']}\")\n",
    "    print(f\"   Category: {rec['category']} | Reason: {rec['reason']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hybrid recommendations\n",
    "hybrid_recs = recommender.hybrid_recommendations(\n",
    "    sample_product_id,\n",
    "    embeddings,\n",
    "    df['id'].tolist(),\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "print(\"Hybrid Recommendations (Best Overall):\\n\")\n",
    "for i, rec in enumerate(hybrid_recs, 1):\n",
    "    print(f\"{i}. {rec['productDisplayName']}\")\n",
    "    print(f\"   Score: {rec['recommendation_score']:.3f}\")\n",
    "    print(f\"   Sources: {rec['recommendation_sources']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mock ground truth for evaluation\n",
    "# In production, this would come from user interactions/clicks\n",
    "\n",
    "relevance_dict = {}\n",
    "results_dict = {}\n",
    "\n",
    "# Simulate 10 queries\n",
    "for i in range(10):\n",
    "    query_id = f\"query_{i}\"\n",
    "    \n",
    "    # Random query\n",
    "    category = np.random.choice(df['category'].unique())\n",
    "    query_text = f\"{category}\"\n",
    "    query_emb = embedder.encode_text(query_text)\n",
    "    \n",
    "    # Get search results\n",
    "    results = search_engine.search(query_emb, top_k=20)\n",
    "    results_dict[query_id] = [r['id'] for r in results]\n",
    "    \n",
    "    # Mock relevance (products in same category are relevant)\n",
    "    relevant = set(df[df['category'] == category]['id'].tolist()[:10])\n",
    "    relevance_dict[query_id] = relevant\n",
    "\n",
    "print(\"Created evaluation data for 10 queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate search system\n",
    "metrics = evaluate_search_system(\n",
    "    relevance_dict,\n",
    "    results_dict,\n",
    "    k_values=[1, 5, 10, 20]\n",
    ")\n",
    "\n",
    "print(\"Search System Evaluation Metrics:\\n\")\n",
    "print(f\"MAP (Mean Average Precision): {metrics['MAP']:.4f}\")\n",
    "print(f\"MRR (Mean Reciprocal Rank): {metrics['MRR']:.4f}\")\n",
    "print(\"\\nMetrics at Different K:\")\n",
    "for k in [1, 5, 10, 20]:\n",
    "    print(f\"\\nK={k}:\")\n",
    "    print(f\"  Precision@{k}: {metrics[f'Precision@{k}']:.4f}\")\n",
    "    print(f\"  Recall@{k}: {metrics[f'Recall@{k}']:.4f}\")\n",
    "    print(f\"  NDCG@{k}: {metrics[f'NDCG@{k}']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize metrics\n",
    "k_values = [1, 5, 10, 20]\n",
    "precision_values = [metrics[f'Precision@{k}'] for k in k_values]\n",
    "recall_values = [metrics[f'Recall@{k}'] for k in k_values]\n",
    "ndcg_values = [metrics[f'NDCG@{k}'] for k in k_values]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(k_values, precision_values, marker='o', label='Precision@K', linewidth=2)\n",
    "ax.plot(k_values, recall_values, marker='s', label='Recall@K', linewidth=2)\n",
    "ax.plot(k_values, ndcg_values, marker='^', label='NDCG@K', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('K', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Search Metrics at Different K Values', fontsize=14)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "✅ **Data Loading & EDA**: Created sample dataset with 100 products  \n",
    "✅ **Visual Search**: CLIP-based semantic search with FAISS  \n",
    "✅ **Recommendations**: Content-based, attribute-based, and hybrid  \n",
    "✅ **Evaluation**: Comprehensive metrics (MAP, MRR, Precision@K, Recall@K, NDCG@K)  \n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Add VLM Integration**: Set up API keys for GPT-4V or Gemini\n",
    "2. **Real Images**: Use actual product images instead of text embeddings\n",
    "3. **Scale Up**: Test with larger datasets (10K+ products)\n",
    "4. **Deploy**: Use the Streamlit app or FastAPI for production\n",
    "5. **Fine-tune**: Customize models for specific product categories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
